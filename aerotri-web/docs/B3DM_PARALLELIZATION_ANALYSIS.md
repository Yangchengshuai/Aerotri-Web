# B3DM 转换并行化方案分析

## 当前问题

当前 B3DM 转换过程是**串行执行**的，对于 518 个 tiles，每个 tile 需要：
1. 生成 glTF 文件（同步操作）
2. 调用 `npx 3d-tiles-tools glbToB3dm` 转换（异步 I/O 操作）
3. 清理中间 glTF 文件

**性能瓶颈**：
- 每个 B3DM 转换大约需要 2-3 秒（包括 npx 启动时间）
- 518 个 tiles × 2.5 秒 ≈ **21.6 分钟**
- 实际观察：169/518 已经转换，说明已经运行了约 7 分钟

## 并行化方案对比

### 方案 1: 异步并发（推荐）⭐

**实现方式**：
- 使用 `asyncio.gather()` 或 `asyncio.Semaphore` 控制并发数
- 将每个 tile 的转换包装为独立的异步任务
- 使用信号量限制同时运行的转换数量（避免资源耗尽）

**优点**：
- 实现简单，代码改动小
- 可以精确控制并发数（如 4-8 个并发）
- 充分利用 I/O 等待时间
- 保持进度跟踪和错误处理

**缺点**：
- npx 启动开销仍然存在（每个任务都要启动 npx）
- 受限于系统资源（CPU、内存、文件句柄）

**预期加速比**：
- 4 并发：约 4x 加速（21.6 分钟 → 5.4 分钟）
- 8 并发：约 6-7x 加速（21.6 分钟 → 3-3.6 分钟）
- 16 并发：约 8-10x 加速（21.6 分钟 → 2.2-2.7 分钟）

**代码示例**：
```python
# 使用 Semaphore 控制并发数
semaphore = asyncio.Semaphore(8)  # 最多 8 个并发

async def convert_tile_with_semaphore(tile, lod_level, ...):
    async with semaphore:
        return await self._convert_gltf_to_b3dm(...)

# 批量执行
tasks = [
    convert_tile_with_semaphore(tile, lod_level, ...)
    for lod_level, tile_list in lod_tiles.items()
    for tile in tile_list
]
results = await asyncio.gather(*tasks, return_exceptions=True)
```

---

### 方案 2: 进程池并行

**实现方式**：
- 使用 `multiprocessing.Pool` 或 `concurrent.futures.ProcessPoolExecutor`
- 每个进程独立执行 B3DM 转换
- 通过进程间通信传递进度

**优点**：
- 真正的并行执行（多核 CPU）
- 进程隔离，单个失败不影响其他

**缺点**：
- 实现复杂（需要序列化数据）
- 进程间通信开销
- 内存占用高（每个进程独立内存空间）
- 进度跟踪复杂

**预期加速比**：
- 4 进程：约 3-4x 加速
- 8 进程：约 5-6x 加速

**适用场景**：
- CPU 密集型任务（当前是 I/O 密集型，不太适合）

---

### 方案 3: 批量处理 + 预启动 npx

**实现方式**：
- 预启动一个长期运行的 `npx 3d-tiles-tools` 进程
- 通过 stdin/stdout 或命名管道传递转换请求
- 批量提交多个转换任务

**优点**：
- 消除 npx 启动开销（每个任务节省 0.5-1 秒）
- 可以批量处理

**缺点**：
- 实现复杂（需要自定义协议）
- 3d-tiles-tools 可能不支持这种模式
- 需要修改工具调用方式

**预期加速比**：
- 约 1.2-1.5x 加速（主要是消除启动开销）

---

### 方案 4: 混合方案（异步并发 + 批量优化）

**实现方式**：
- 使用方案 1 的异步并发
- 优化 glTF 生成（批量生成）
- 优化文件清理（延迟批量清理）

**优点**：
- 结合多种优化手段
- 实现相对简单

**预期加速比**：
- 约 6-8x 加速（相比纯串行）

---

## 推荐方案

**推荐使用方案 1（异步并发）**，原因：
1. ✅ 实现简单，代码改动小
2. ✅ 充分利用 I/O 等待时间
3. ✅ 可以精确控制资源使用
4. ✅ 保持现有的错误处理和进度跟踪
5. ✅ 预期 4-8x 加速，足够满足需求

## 实现细节

### 并发数选择

建议根据系统资源动态调整：
- **默认**：8 个并发（适合大多数情况）
- **高配置服务器**：16 个并发
- **低配置**：4 个并发

可以通过配置参数控制：
```python
max_concurrent_b3dm = convert_params.get("max_concurrent_b3dm", 8)
```

### 进度跟踪优化

并行执行时，进度更新需要优化：
- 使用原子计数器跟踪已完成的 tiles
- 减少数据库更新频率（每完成 10 个 tiles 更新一次，而不是每个）
- 使用内存中的进度缓存

### 错误处理

- 使用 `return_exceptions=True` 捕获所有异常
- 记录每个失败的 tile，但不中断整体流程
- 在最后汇总所有失败信息

## 性能预估

**当前（串行）**：
- 518 tiles × 2.5 秒 = **21.6 分钟**

**优化后（8 并发）**：
- 518 tiles ÷ 8 × 2.5 秒 = **2.7 分钟**
- **加速比：约 8x**

**优化后（16 并发）**：
- 518 tiles ÷ 16 × 2.5 秒 = **1.35 分钟**
- **加速比：约 16x**（但可能受 I/O 限制，实际约 10-12x）

## 风险评估

1. **资源耗尽**：过多并发可能导致内存或文件句柄耗尽
   - 缓解：使用 Semaphore 限制并发数

2. **npx 进程过多**：每个并发任务都会启动一个 npx 进程
   - 缓解：限制并发数，监控系统资源

3. **进度跟踪延迟**：并行执行时进度更新可能不够实时
   - 缓解：使用内存缓存 + 定期批量更新数据库

## 实施建议

1. **第一阶段**：实现方案 1（异步并发，8 并发）
2. **测试验证**：在小数据集上测试（如 50 个 tiles）
3. **性能监控**：监控 CPU、内存、I/O 使用情况
4. **调优**：根据实际性能调整并发数
5. **第二阶段**（可选）：如果还不够快，考虑方案 4（混合优化）
